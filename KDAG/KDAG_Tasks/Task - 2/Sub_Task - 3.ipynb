{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d36c91d4",
   "metadata": {},
   "source": [
    "# Gaussian Discrminative Analysis Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deed00f",
   "metadata": {},
   "source": [
    "In this subtask, Gaussian Discriminative Analysis model's hyperparameters are tuned on 'ds1_train.csv' and then tested on 'ds1_test.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4e2b5e",
   "metadata": {},
   "source": [
    "The required libraries for this task are numpy and pandas.\n",
    "\n",
    "Numpy is used to create array and its functions are used such as exponential function, dot product, transpose of a matrix etc.\n",
    "\n",
    "Pandas is used to read data from the csv files and convert it into list of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a93a21f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f3a836",
   "metadata": {},
   "source": [
    "The data from the csv files are extracted by pandas.read_csv function where it reads the data from the csv file and converts it into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c3ef686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the traning and test examples\n",
    "# df_train represents the traning DataFrame\n",
    "\n",
    "df_train = pd.read_csv('ds2_train.csv')\n",
    "df_test = pd.read_csv('ds2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb2d09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.759481</td>\n",
       "      <td>7.507940</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.422057</td>\n",
       "      <td>4.991203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.778818</td>\n",
       "      <td>4.112071</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.018066</td>\n",
       "      <td>5.653732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.806062</td>\n",
       "      <td>4.685966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.882302</td>\n",
       "      <td>5.123573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.189999</td>\n",
       "      <td>5.424746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.104426</td>\n",
       "      <td>2.480323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.771032</td>\n",
       "      <td>3.059402</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.397404</td>\n",
       "      <td>5.148616</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2    y\n",
       "0  3.759481  7.507940  0.0\n",
       "1  3.422057  4.991203  0.0\n",
       "2  2.778818  4.112071  0.0\n",
       "3  4.018066  5.653732  0.0\n",
       "4  1.806062  4.685966  0.0\n",
       "5  2.882302  5.123573  0.0\n",
       "6  3.189999  5.424746  0.0\n",
       "7  2.104426  2.480323  0.0\n",
       "8  1.771032  3.059402  0.0\n",
       "9  3.397404  5.148616  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the datframe df_train to see the type of data\n",
    "# pandas.head(n) function is used to print the first n data entries of the respective dataframe. By default n=5\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2ffa81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1    0\n",
      "x_2    0\n",
      "y      0\n",
      "dtype: int64\n",
      "x_1    0\n",
      "x_2    0\n",
      "y      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# It's important to check for the null values in both the training and the test dataset\n",
    "\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88fe2f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    400\n",
       "1.0    400\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the data entries of column y to see the types of labels\n",
    "# pandas.value_counts() function is used to print the number of distinct entries in a particular coulmn\n",
    "\n",
    "df_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f1a6507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7594805 , 7.5079397 ],\n",
       "       [3.42205706, 4.99120267],\n",
       "       [2.77881751, 4.11207082],\n",
       "       ...,\n",
       "       [3.54410545, 2.64987938],\n",
       "       [2.57546055, 2.51725473],\n",
       "       [3.5608151 , 3.99184993]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperating the X and y of training data\n",
    "# pandas.values function converts the data of DataFrame into array\n",
    "\n",
    "X_train = df_train[['x_1', 'x_2']].values\n",
    "y_train = df_train['y'].values\n",
    "\n",
    "X_test = df_test[['x_1', 'x_2']].values\n",
    "y_test = df_test['y'].values\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001651e",
   "metadata": {},
   "source": [
    "It is clear that this model has two labels 0 and 1. So Gaussian Discriminative Analysis would work fine for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faee00de",
   "metadata": {},
   "source": [
    "### Declaring the modal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e684daf3",
   "metadata": {},
   "source": [
    "In GDA model, the prediction is based on the basis of probabilities of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515ccb85",
   "metadata": {},
   "source": [
    "The probablity of the input data is calculated in the basis of three parameters; mu, sigma and phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694748aa",
   "metadata": {},
   "source": [
    "mu refers to the mean of the individual features of a particular class. So it will be a matrix of order d x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a29e91c",
   "metadata": {},
   "source": [
    "sigma refers to the covariance matrix of each class between its variuos features. So it will be a matrix of order d x d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd03475c",
   "metadata": {},
   "source": [
    "class prior refers to the probability of occurance each class in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121a61a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of data\n",
    "# numpy.shape gives the number of rows and columns in a form of tuple\n",
    "# Here y_train.shpe[0] gives the shape of the y_train array and the zero index specifies the number of rows in it.\n",
    "\n",
    "n = y_train.shape[0]\n",
    "\n",
    "n_0 = df_train[df_train['y'] == 0]['y'].count() # n_0=400\n",
    "n_1 = df_train[df_train['y'] == 1]['y'].count() # n_1=400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cd9a21",
   "metadata": {},
   "source": [
    "Mean of the data is average of data inputs. It is ratio of the sum of the total correct entries and total number of entries.\n",
    "\n",
    "To calculate the mean of the features of the respective classes, firstly the classes should be divided into the respective groups on the bais of labels and then thier respective means should be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31096ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean matrix\n",
    "# mu_0 represents the mean of the features belonging to class 0\n",
    "# Firstly the df_train is sorted according to the class labels\n",
    "# df_train['y'] == 0 will give true and false thereby distinguishing the dataset on the class labels\n",
    "# Then the respective features are selected to be meaned.\n",
    "# np.mean() calculates the mean of the input entries\n",
    "\n",
    "mu_0 = df_train[df_train['y'] == 0][['x_1', 'x_2']].mean()\n",
    "\n",
    "# mu_1 represents the mean of the features belonging to class 1\n",
    "# df_train['y'] == 1 will give true and false thereby distinguishing the dataset on the class labels\n",
    "\n",
    "mu_1 = df_train[df_train['y'] == 1][['x_1', 'x_2']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fae40f5",
   "metadata": {},
   "source": [
    "For Covariance, firstly individual covariances are calculated of individual classes and then the pooled covariance is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a7dd472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Covariance matrix sigma and then pooled sigma\n",
    "# df_train['y'] == 0 will give true and false thereby distinguishing the dataset on the class labels\n",
    "# np.cov will calculate the covariance matrix  of the given data\n",
    "\n",
    "sigma_0 = df_train[df_train['y'] == 0][['x_1', 'x_2']].cov().values\n",
    "sigma_1 = df_train[df_train['y'] == 1][['x_1', 'x_2']].cov().values\n",
    "\n",
    "# Now the pooled sigma is calculated using the below formula\n",
    "\n",
    "pooled_sigma = (sigma_0 * (n_0 - 1) + sigma_1 * (n_1 - 1)) / (n_0 + n_1 - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "199b8658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma_0\n",
      " [[0.93996737 0.65326934]\n",
      " [0.65326934 0.9372294 ]]\n",
      "Sigma_1\n",
      " [[1.01781642 0.74399449]\n",
      " [0.74399449 0.95598585]]\n",
      "Pooled_sigma\n",
      " [[0.9788919  0.69863192]\n",
      " [0.69863192 0.94660762]]\n"
     ]
    }
   ],
   "source": [
    "# Printing sigma_0, sigma_1 and pooled sigma\n",
    "\n",
    "print(\"Sigma_0\\n\", sigma_0)\n",
    "print(\"Sigma_1\\n\", sigma_1)\n",
    "print('Pooled_sigma\\n', pooled_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b264ac",
   "metadata": {},
   "source": [
    "Notice that in all the above sigmas the non-diagonal elements are the same.\n",
    "\n",
    "It is because it is calculated as follows:\n",
    "\n",
    "The first element of a sigma matrix is the covariance between the first and the first element.\n",
    "\n",
    "The second element of a sigma matrix is the covariance between the first and the second element.\n",
    "\n",
    "The third element of a sigma matrix is the covariance between the second and the first element.\n",
    "\n",
    "The fourth element of a sigma matrix is the covariance between the second and the second element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7fd077",
   "metadata": {},
   "source": [
    "### Defining the Gaussian Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af874f",
   "metadata": {},
   "source": [
    "In this function, it calculates the likelihood of an input feature for both the classes\n",
    "\n",
    "Based on that information that input feature will be predicted to be the oart of the one with more likelihood value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbe22e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Gaussian_Analysis Function\n",
    "# When it takes the X as input, it calculates it probability of belonging to both the classes\n",
    "# It returns 1 if the probability of it belonging to class 1 is more than the class 0\n",
    "# It returns 0 if the probability of it belonging to class 0 is more than the class 1\n",
    "\n",
    "def gaussian_analysis(x, prior_0, prior_1, sigma):\n",
    "    \n",
    "    # np.dot function is used to calculate the product of matrices\n",
    "    # np.linalg.inv() is uded to calculate the inverse of the sigma matrix\n",
    "    # Here pooled sigma is used beacuse it is assumed that both the gaussian distributions are based on the same covariance matrix\n",
    "    \n",
    "    # Calculating log likelihood for Class 0\n",
    "    # mu_0 represents the mean of class 0 of features x_1 and x_2\n",
    "    # phi[0] represents the probability of occurance of Class 0 in whole dataset\n",
    "    \n",
    "    prob_0 = -0.5 * np.dot(np.dot((x - mu_0).T, np.linalg.inv(sigma[0])), x - mu_0) + np.log(prior_0)\n",
    "    \n",
    "    # Calculating log likelihood for Class 1\n",
    "    # mu_1 represents the mean of class 1 of features x_1 and x_2\n",
    "    # phi[1] represents the probability of occurance of Class 1 in whole dataset\n",
    "    \n",
    "    prob_1 = -0.5 * np.dot(np.dot((x - mu_1).T, np.linalg.inv(sigma[1])), x - mu_1) + np.log(prior_1)\n",
    "    \n",
    "    # The probability of both the classes are compared and thus returns the class label to which it should belong\n",
    "    \n",
    "    if prob_0 < prob_1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd5bccb",
   "metadata": {},
   "source": [
    "### GDA has a hyperparamter class prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490b1ca7",
   "metadata": {},
   "source": [
    "Class Prior is factor that is equal to the probability of occuring of a class in the whole dataset.\n",
    "\n",
    "It might be possible that the value acquired from the dataset is not the ideal data for maximum accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac3f940",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334af15d",
   "metadata": {},
   "source": [
    "GridSearch is a technique for hyperparameter tuning and model selection in machine learning. It is a systematic way of searching through a predefined set of hyperparameter values to find the combination that yields the best model performance. GridSearch is commonly used to optimize the hyperparameters of a machine learning model and improve its generalization on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e2bedaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters for hypertuning\n",
    "# np.linspace creates an array of the data range provided in it with equal spacing\n",
    "# Defining the prior_0 class as np.linspace\n",
    "\n",
    "prior_0 = np.linspace(0.01, 0.99, 200)\n",
    "\n",
    "# Defining the prior_1 as the difference of prior_0 with 1 as it follows Bernoulli Distribution\n",
    "\n",
    "prior_1 = 1 - prior_0\n",
    "\n",
    "# Covariance Matrix may also be hypertuned\n",
    "# Either individual covariances matrices are used or the pooled covariance matrix is used\n",
    "\n",
    "sigma = [[pooled_sigma, pooled_sigma], [sigma_0, sigma_1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e947f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch function\n",
    "# It takes many parameters such as X_train, y_train, X_test, y_test, prior, sigma\n",
    "# X_train is the traning set and contains features to be trained\n",
    "# y_train is the training set column and conatins labels to be compared with\n",
    "# prior is the class prior value of class 0 \n",
    "# sigma is the covariance matrix \n",
    "\n",
    "def GridSearch(prior, sigma, X_train, y_train):\n",
    "    \n",
    "    # Defining the shapes to have the separate row and column values\n",
    "    # The row values will be used to get the number of times the for loop is going to run\n",
    "    # Defining for the training set\n",
    "    \n",
    "    m_train, n_train = X_train.shape\n",
    "    \n",
    "    # Initialising each calculating term to be zero\n",
    "    \n",
    "    max_accur = 0\n",
    "    pri_0 = 0\n",
    "    pri_1 = 0\n",
    "    sigm = [0,0]\n",
    "    \n",
    "    # Implementing GridSearch\n",
    "    # Defining the for loop to run \n",
    "    # First loop is the loop running through prior parameter list\n",
    "    # Second loop is the loop running through covariance matrix list\n",
    "    \n",
    "    for pr in prior:\n",
    "        for sig in sigma:\n",
    "            \n",
    "            # Declaring training set accuracy score\n",
    "            \n",
    "            train_score = 0\n",
    "            \n",
    "            # Defining the class prior for class 0\n",
    "            \n",
    "            prior_0 = pr\n",
    "            \n",
    "            # Defining the class prior for class 1\n",
    "            \n",
    "            prior_1 = 1 - pr\n",
    "            \n",
    "            # Defining the for loop which calculates the accuracy score of the training set\n",
    "            \n",
    "            for i in range(m_train):\n",
    "                \n",
    "                # It checks if the predicted value is equal to label\n",
    "                \n",
    "                if gaussian_analysis(X_train[i], prior_0, prior_1, sig) == y_train[i]:\n",
    "                    train_score = train_score + 1\n",
    "            \n",
    "            # Calculates the accuracy score\n",
    "            \n",
    "            train_accur = train_score/m_train\n",
    "            print(train_accur,'  ', prior_0)\n",
    "            \n",
    "            # Updates the maximum accurcay\n",
    "            # Correspondingly stores the other requires parameters\n",
    "            \n",
    "            if train_accur > max_accur:\n",
    "                max_accur = train_accur\n",
    "                pri_0 = pr\n",
    "                sigm = sig\n",
    "    \n",
    "    # Returning the parameters that will be used in calculating the test accuracy\n",
    "    \n",
    "    return max_accur, pri_0, sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3019663",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69875    0.01\n",
      "0.7225    0.01\n",
      "0.725    0.014924623115577889\n",
      "0.7575    0.014924623115577889\n",
      "0.75625    0.01984924623115578\n",
      "0.77375    0.01984924623115578\n",
      "0.77    0.024773869346733667\n",
      "0.78625    0.024773869346733667\n",
      "0.77625    0.029698492462311557\n",
      "0.8    0.029698492462311557\n",
      "0.78875    0.03462311557788945\n",
      "0.80625    0.03462311557788945\n",
      "0.80125    0.03954773869346734\n",
      "0.8125    0.03954773869346734\n",
      "0.8125    0.04447236180904523\n",
      "0.82    0.04447236180904523\n",
      "0.81125    0.04939698492462312\n",
      "0.82875    0.04939698492462312\n",
      "0.81875    0.05432160804020101\n",
      "0.8375    0.05432160804020101\n",
      "0.82875    0.0592462311557789\n",
      "0.84375    0.0592462311557789\n",
      "0.83375    0.06417085427135678\n",
      "0.845    0.06417085427135678\n",
      "0.84    0.06909547738693467\n",
      "0.8475    0.06909547738693467\n",
      "0.845    0.07402010050251256\n",
      "0.8525    0.07402010050251256\n",
      "0.845    0.07894472361809045\n",
      "0.85375    0.07894472361809045\n",
      "0.84625    0.08386934673366835\n",
      "0.85625    0.08386934673366835\n",
      "0.85125    0.08879396984924623\n",
      "0.855    0.08879396984924623\n",
      "0.85375    0.09371859296482411\n",
      "0.86375    0.09371859296482411\n",
      "0.85625    0.09864321608040201\n",
      "0.87    0.09864321608040201\n",
      "0.85875    0.1035678391959799\n",
      "0.87375    0.1035678391959799\n",
      "0.86125    0.10849246231155779\n",
      "0.875    0.10849246231155779\n",
      "0.86625    0.11341708542713567\n",
      "0.875    0.11341708542713567\n",
      "0.86875    0.11834170854271357\n",
      "0.87625    0.11834170854271357\n",
      "0.8725    0.12326633165829146\n",
      "0.88    0.12326633165829146\n",
      "0.87375    0.12819095477386935\n",
      "0.88125    0.12819095477386935\n",
      "0.87625    0.13311557788944725\n",
      "0.885    0.13311557788944725\n",
      "0.87875    0.13804020100502515\n",
      "0.88625    0.13804020100502515\n",
      "0.88    0.14296482412060302\n",
      "0.89    0.14296482412060302\n",
      "0.8825    0.14788944723618092\n",
      "0.89125    0.14788944723618092\n",
      "0.88375    0.1528140703517588\n",
      "0.8925    0.1528140703517588\n",
      "0.885    0.1577386934673367\n",
      "0.895    0.1577386934673367\n",
      "0.88625    0.16266331658291458\n",
      "0.895    0.16266331658291458\n",
      "0.8875    0.16758793969849248\n",
      "0.89375    0.16758793969849248\n",
      "0.89125    0.17251256281407037\n",
      "0.89375    0.17251256281407037\n",
      "0.89375    0.17743718592964824\n",
      "0.89375    0.17743718592964824\n",
      "0.89375    0.18236180904522614\n",
      "0.895    0.18236180904522614\n",
      "0.895    0.18728643216080404\n",
      "0.8975    0.18728643216080404\n",
      "0.895    0.19221105527638194\n",
      "0.89875    0.19221105527638194\n",
      "0.89625    0.1971356783919598\n",
      "0.90125    0.1971356783919598\n",
      "0.895    0.2020603015075377\n",
      "0.9025    0.2020603015075377\n",
      "0.89375    0.2069849246231156\n",
      "0.9025    0.2069849246231156\n",
      "0.89375    0.21190954773869347\n",
      "0.90375    0.21190954773869347\n",
      "0.8975    0.21683417085427137\n",
      "0.90375    0.21683417085427137\n",
      "0.9    0.22175879396984927\n",
      "0.90375    0.22175879396984927\n",
      "0.90125    0.22668341708542716\n",
      "0.90375    0.22668341708542716\n",
      "0.9025    0.23160804020100503\n",
      "0.905    0.23160804020100503\n",
      "0.905    0.23653266331658293\n",
      "0.9075    0.23653266331658293\n",
      "0.905    0.24145728643216083\n",
      "0.90875    0.24145728643216083\n",
      "0.905    0.2463819095477387\n",
      "0.91    0.2463819095477387\n",
      "0.905    0.2513065326633166\n",
      "0.90875    0.2513065326633166\n",
      "0.90375    0.2562311557788945\n",
      "0.90875    0.2562311557788945\n",
      "0.90625    0.2611557788944724\n",
      "0.9075    0.2611557788944724\n",
      "0.90625    0.2660804020100503\n",
      "0.9075    0.2660804020100503\n",
      "0.90875    0.2710050251256282\n",
      "0.9075    0.2710050251256282\n",
      "0.90875    0.275929648241206\n",
      "0.90625    0.275929648241206\n",
      "0.9125    0.2808542713567839\n",
      "0.905    0.2808542713567839\n",
      "0.91125    0.2857788944723618\n",
      "0.9075    0.2857788944723618\n",
      "0.91    0.2907035175879397\n",
      "0.9075    0.2907035175879397\n",
      "0.91125    0.2956281407035176\n",
      "0.9075    0.2956281407035176\n",
      "0.91    0.3005527638190955\n",
      "0.9075    0.3005527638190955\n",
      "0.90875    0.3054773869346734\n",
      "0.9075    0.3054773869346734\n",
      "0.90625    0.31040201005025125\n",
      "0.9075    0.31040201005025125\n",
      "0.905    0.31532663316582915\n",
      "0.90875    0.31532663316582915\n",
      "0.905    0.32025125628140705\n",
      "0.90875    0.32025125628140705\n",
      "0.905    0.32517587939698495\n",
      "0.90625    0.32517587939698495\n",
      "0.90625    0.33010050251256284\n",
      "0.90625    0.33010050251256284\n",
      "0.9075    0.33502512562814074\n",
      "0.90875    0.33502512562814074\n",
      "0.90625    0.33994974874371864\n",
      "0.9075    0.33994974874371864\n",
      "0.90625    0.3448743718592965\n",
      "0.9075    0.3448743718592965\n",
      "0.90625    0.3497989949748744\n",
      "0.90625    0.3497989949748744\n",
      "0.9075    0.3547236180904523\n",
      "0.90625    0.3547236180904523\n",
      "0.9075    0.3596482412060302\n",
      "0.9075    0.3596482412060302\n",
      "0.90625    0.36457286432160807\n",
      "0.90875    0.36457286432160807\n",
      "0.90625    0.36949748743718597\n",
      "0.90875    0.36949748743718597\n",
      "0.9075    0.37442211055276386\n",
      "0.90875    0.37442211055276386\n",
      "0.9075    0.3793467336683417\n",
      "0.90875    0.3793467336683417\n",
      "0.9075    0.3842713567839196\n",
      "0.90875    0.3842713567839196\n",
      "0.90625    0.3891959798994975\n",
      "0.90875    0.3891959798994975\n",
      "0.90875    0.3941206030150754\n",
      "0.90875    0.3941206030150754\n",
      "0.90875    0.3990452261306533\n",
      "0.90875    0.3990452261306533\n",
      "0.90875    0.4039698492462312\n",
      "0.91    0.4039698492462312\n",
      "0.91    0.4088944723618091\n",
      "0.91125    0.4088944723618091\n",
      "0.91    0.41381909547738693\n",
      "0.91125    0.41381909547738693\n",
      "0.91    0.41874371859296483\n",
      "0.91    0.41874371859296483\n",
      "0.91    0.42366834170854273\n",
      "0.91125    0.42366834170854273\n",
      "0.91    0.4285929648241206\n",
      "0.91125    0.4285929648241206\n",
      "0.91    0.4335175879396985\n",
      "0.9125    0.4335175879396985\n",
      "0.91    0.4384422110552764\n",
      "0.9125    0.4384422110552764\n",
      "0.91125    0.4433668341708543\n",
      "0.9125    0.4433668341708543\n",
      "0.91125    0.44829145728643216\n",
      "0.9125    0.44829145728643216\n",
      "0.91125    0.45321608040201006\n",
      "0.91375    0.45321608040201006\n",
      "0.91    0.45814070351758795\n",
      "0.9125    0.45814070351758795\n",
      "0.91125    0.46306532663316585\n",
      "0.91375    0.46306532663316585\n",
      "0.91125    0.46798994974874375\n",
      "0.91375    0.46798994974874375\n",
      "0.9125    0.47291457286432165\n",
      "0.91375    0.47291457286432165\n",
      "0.9125    0.47783919597989954\n",
      "0.91375    0.47783919597989954\n",
      "0.91375    0.4827638190954774\n",
      "0.91625    0.4827638190954774\n",
      "0.91375    0.4876884422110553\n",
      "0.915    0.4876884422110553\n",
      "0.91375    0.4926130653266332\n",
      "0.9175    0.4926130653266332\n",
      "0.91375    0.4975376884422111\n",
      "0.91625    0.4975376884422111\n",
      "0.91375    0.502462311557789\n",
      "0.91625    0.502462311557789\n",
      "0.9125    0.5073869346733668\n",
      "0.915    0.5073869346733668\n",
      "0.91375    0.5123115577889448\n",
      "0.91375    0.5123115577889448\n",
      "0.915    0.5172361809045226\n",
      "0.91375    0.5172361809045226\n",
      "0.91625    0.5221608040201006\n",
      "0.91375    0.5221608040201006\n",
      "0.91625    0.5270854271356784\n",
      "0.91375    0.5270854271356784\n",
      "0.91625    0.5320100502512564\n",
      "0.91375    0.5320100502512564\n",
      "0.915    0.5369346733668342\n",
      "0.91375    0.5369346733668342\n",
      "0.915    0.541859296482412\n",
      "0.91375    0.541859296482412\n",
      "0.91375    0.54678391959799\n",
      "0.9125    0.54678391959799\n",
      "0.915    0.5517085427135678\n",
      "0.91375    0.5517085427135678\n",
      "0.915    0.5566331658291458\n",
      "0.91375    0.5566331658291458\n",
      "0.915    0.5615577889447236\n",
      "0.91375    0.5615577889447236\n",
      "0.915    0.5664824120603016\n",
      "0.915    0.5664824120603016\n",
      "0.91125    0.5714070351758794\n",
      "0.915    0.5714070351758794\n",
      "0.91125    0.5763316582914573\n",
      "0.91625    0.5763316582914573\n",
      "0.9125    0.5812562814070352\n",
      "0.915    0.5812562814070352\n",
      "0.9125    0.5861809045226131\n",
      "0.915    0.5861809045226131\n",
      "0.9125    0.591105527638191\n",
      "0.915    0.591105527638191\n",
      "0.9125    0.5960301507537689\n",
      "0.915    0.5960301507537689\n",
      "0.9125    0.6009547738693468\n",
      "0.91125    0.6009547738693468\n",
      "0.915    0.6058793969849247\n",
      "0.91    0.6058793969849247\n",
      "0.915    0.6108040201005025\n",
      "0.91    0.6108040201005025\n",
      "0.915    0.6157286432160805\n",
      "0.91125    0.6157286432160805\n",
      "0.9125    0.6206532663316583\n",
      "0.91    0.6206532663316583\n",
      "0.9125    0.6255778894472362\n",
      "0.91    0.6255778894472362\n",
      "0.91125    0.6305025125628141\n",
      "0.9075    0.6305025125628141\n",
      "0.91    0.635427135678392\n",
      "0.90875    0.635427135678392\n",
      "0.91125    0.6403517587939699\n",
      "0.91    0.6403517587939699\n",
      "0.9125    0.6452763819095477\n",
      "0.91    0.6452763819095477\n",
      "0.9125    0.6502010050251257\n",
      "0.90875    0.6502010050251257\n",
      "0.91125    0.6551256281407035\n",
      "0.90875    0.6551256281407035\n",
      "0.91    0.6600502512562815\n",
      "0.90875    0.6600502512562815\n",
      "0.90875    0.6649748743718593\n",
      "0.9075    0.6649748743718593\n",
      "0.91    0.6698994974874373\n",
      "0.9075    0.6698994974874373\n",
      "0.91    0.6748241206030151\n",
      "0.90625    0.6748241206030151\n",
      "0.91    0.679748743718593\n",
      "0.91    0.679748743718593\n",
      "0.90875    0.6846733668341709\n",
      "0.9075    0.6846733668341709\n",
      "0.90875    0.6895979899497487\n",
      "0.9075    0.6895979899497487\n",
      "0.90875    0.6945226130653267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9075    0.6945226130653267\n",
      "0.9075    0.6994472361809045\n",
      "0.9075    0.6994472361809045\n",
      "0.9075    0.7043718592964825\n",
      "0.9075    0.7043718592964825\n",
      "0.905    0.7092964824120603\n",
      "0.90875    0.7092964824120603\n",
      "0.90875    0.7142211055276382\n",
      "0.9075    0.7142211055276382\n",
      "0.90875    0.7191457286432161\n",
      "0.90625    0.7191457286432161\n",
      "0.9075    0.724070351758794\n",
      "0.90375    0.724070351758794\n",
      "0.9075    0.7289949748743719\n",
      "0.905    0.7289949748743719\n",
      "0.9075    0.7339195979899498\n",
      "0.905    0.7339195979899498\n",
      "0.9075    0.7388442211055277\n",
      "0.9075    0.7388442211055277\n",
      "0.90875    0.7437688442211056\n",
      "0.90625    0.7437688442211056\n",
      "0.9075    0.7486934673366834\n",
      "0.90375    0.7486934673366834\n",
      "0.905    0.7536180904522614\n",
      "0.90375    0.7536180904522614\n",
      "0.90625    0.7585427135678392\n",
      "0.90375    0.7585427135678392\n",
      "0.905    0.7634673366834172\n",
      "0.9025    0.7634673366834172\n",
      "0.905    0.768391959798995\n",
      "0.9025    0.768391959798995\n",
      "0.905    0.773316582914573\n",
      "0.90125    0.773316582914573\n",
      "0.905    0.7782412060301508\n",
      "0.89625    0.7782412060301508\n",
      "0.90375    0.7831658291457286\n",
      "0.89375    0.7831658291457286\n",
      "0.90375    0.7880904522613066\n",
      "0.8925    0.7880904522613066\n",
      "0.9025    0.7930150753768844\n",
      "0.89    0.7930150753768844\n",
      "0.89875    0.7979396984924624\n",
      "0.8875    0.7979396984924624\n",
      "0.89875    0.8028643216080402\n",
      "0.88625    0.8028643216080402\n",
      "0.89375    0.8077889447236182\n",
      "0.88625    0.8077889447236182\n",
      "0.89125    0.812713567839196\n",
      "0.885    0.812713567839196\n",
      "0.88875    0.8176381909547739\n",
      "0.8825    0.8176381909547739\n",
      "0.8875    0.8225628140703518\n",
      "0.8825    0.8225628140703518\n",
      "0.8875    0.8274874371859297\n",
      "0.8825    0.8274874371859297\n",
      "0.88625    0.8324120603015076\n",
      "0.88    0.8324120603015076\n",
      "0.8825    0.8373366834170854\n",
      "0.88    0.8373366834170854\n",
      "0.8825    0.8422613065326634\n",
      "0.87625    0.8422613065326634\n",
      "0.8825    0.8471859296482412\n",
      "0.875    0.8471859296482412\n",
      "0.8825    0.8521105527638191\n",
      "0.875    0.8521105527638191\n",
      "0.87875    0.857035175879397\n",
      "0.87375    0.857035175879397\n",
      "0.87625    0.8619597989949749\n",
      "0.87125    0.8619597989949749\n",
      "0.87375    0.8668844221105528\n",
      "0.87125    0.8668844221105528\n",
      "0.87375    0.8718090452261307\n",
      "0.87    0.8718090452261307\n",
      "0.87375    0.8767336683417086\n",
      "0.86375    0.8767336683417086\n",
      "0.8725    0.8816582914572865\n",
      "0.8625    0.8816582914572865\n",
      "0.86875    0.8865829145728643\n",
      "0.86125    0.8865829145728643\n",
      "0.86625    0.8915075376884423\n",
      "0.85875    0.8915075376884423\n",
      "0.8625    0.8964321608040201\n",
      "0.85625    0.8964321608040201\n",
      "0.86125    0.9013567839195981\n",
      "0.8525    0.9013567839195981\n",
      "0.85875    0.9062814070351759\n",
      "0.8475    0.9062814070351759\n",
      "0.855    0.9112060301507539\n",
      "0.8475    0.9112060301507539\n",
      "0.85    0.9161306532663317\n",
      "0.83875    0.9161306532663317\n",
      "0.84625    0.9210552763819095\n",
      "0.8325    0.9210552763819095\n",
      "0.8475    0.9259798994974875\n",
      "0.83    0.9259798994974875\n",
      "0.83625    0.9309045226130653\n",
      "0.82375    0.9309045226130653\n",
      "0.83125    0.9358291457286433\n",
      "0.825    0.9358291457286433\n",
      "0.82875    0.9407537688442211\n",
      "0.825    0.9407537688442211\n",
      "0.825    0.9456783919597991\n",
      "0.81875    0.9456783919597991\n",
      "0.82375    0.9506030150753769\n",
      "0.8125    0.9506030150753769\n",
      "0.81875    0.9555276381909548\n",
      "0.8    0.9555276381909548\n",
      "0.80625    0.9604522613065327\n",
      "0.79    0.9604522613065327\n",
      "0.79625    0.9653768844221106\n",
      "0.78    0.9653768844221106\n",
      "0.78375    0.9703015075376885\n",
      "0.77125    0.9703015075376885\n",
      "0.77    0.9752261306532664\n",
      "0.7525    0.9752261306532664\n",
      "0.7525    0.9801507537688443\n",
      "0.73625    0.9801507537688443\n",
      "0.735    0.9850753768844221\n",
      "0.70625    0.9850753768844221\n",
      "0.69625    0.99\n",
      "0.675    0.99\n"
     ]
    }
   ],
   "source": [
    "# Calling the GridSearch function\n",
    "# max_accur stores the maximum accuracy of the train set\n",
    "# prior_0 stores the class prior of class 0 corresponding to maximum accuracy\n",
    "# sigma stores the covariance matrix corresponding to the maximum accuracy\n",
    "\n",
    "max_accur, prior_0, sigma = GridSearch(prior_0, sigma, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7752428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters\n",
      "prior_0  0.4926130653266332\n",
      "sigma  [array([[0.93996737, 0.65326934],\n",
      "       [0.65326934, 0.9372294 ]]), array([[1.01781642, 0.74399449],\n",
      "       [0.74399449, 0.95598585]])]\n",
      "maximum accuracy of the training set is:  0.9175\n"
     ]
    }
   ],
   "source": [
    "# Printing the best parameters\n",
    "\n",
    "print('Best Parameters')\n",
    "print('prior_0 ', prior_0)\n",
    "print('sigma ', sigma)\n",
    "print('maximum accuracy of the training set is: ', max_accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b68b36ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_accur:  0.91\n"
     ]
    }
   ],
   "source": [
    "# Defining the shapes to have the separate row and column values\n",
    "# The row values will be used to get the number of times the for loop is going to run\n",
    "# np.shape gives the no. of rows and columns \n",
    "\n",
    "m_test, n_test = X_test.shape\n",
    "\n",
    "# Defining the for loop which calculates the accuracy score of the training set\n",
    "# Defining the variable for calculating test score\n",
    "\n",
    "test_score = 0\n",
    "for i in range(m_test):\n",
    "    \n",
    "    # Calculates the accuracy score of the test dataset\n",
    "    \n",
    "    if gaussian_analysis(X_test[i], prior_0, 1-prior_0, sigma) == y_test[i]:\n",
    "        test_score = test_score + 1\n",
    "\n",
    "test_accur = test_score/m_test\n",
    "print('test_accur: ', test_accur)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b028e",
   "metadata": {},
   "source": [
    "# Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
