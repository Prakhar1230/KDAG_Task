{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7692885b",
   "metadata": {},
   "source": [
    "# Gaussian Discrminative Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660d3c3",
   "metadata": {},
   "source": [
    "In this subtask, Gaussian Discriminative Analysis model is used to train on 'ds1_train.csv' and then tested on 'ds1_test.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af04379f",
   "metadata": {},
   "source": [
    "The required libraries for this task are numpy and pandas.\n",
    "\n",
    "Numpy is used to create array and its functions are used such as exponential function, dot product, transpose of a matrix etc.\n",
    "\n",
    "Pandas is used to read data from the csv files and convert it into list of arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ced4b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847133cf",
   "metadata": {},
   "source": [
    "The data from the csv files are extracted by pandas.read_csv function where it reads the data from the csv file and converts it into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "530df596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the traning and test examples\n",
    "# df_train represents the traning DataFrame\n",
    "\n",
    "df_train = pd.read_csv('ds2_train.csv')\n",
    "df_test = pd.read_csv('ds2_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ac160f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.759481</td>\n",
       "      <td>7.507940</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.422057</td>\n",
       "      <td>4.991203</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.778818</td>\n",
       "      <td>4.112071</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.018066</td>\n",
       "      <td>5.653732</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.806062</td>\n",
       "      <td>4.685966</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.882302</td>\n",
       "      <td>5.123573</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.189999</td>\n",
       "      <td>5.424746</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.104426</td>\n",
       "      <td>2.480323</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.771032</td>\n",
       "      <td>3.059402</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.397404</td>\n",
       "      <td>5.148616</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1       x_2    y\n",
       "0  3.759481  7.507940  0.0\n",
       "1  3.422057  4.991203  0.0\n",
       "2  2.778818  4.112071  0.0\n",
       "3  4.018066  5.653732  0.0\n",
       "4  1.806062  4.685966  0.0\n",
       "5  2.882302  5.123573  0.0\n",
       "6  3.189999  5.424746  0.0\n",
       "7  2.104426  2.480323  0.0\n",
       "8  1.771032  3.059402  0.0\n",
       "9  3.397404  5.148616  0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the datframe df_train to see the type of data\n",
    "# pandas.head(n) function is used to print the first n data entries of the respective dataframe. By default n=5\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6ce74fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1    0\n",
      "x_2    0\n",
      "y      0\n",
      "dtype: int64\n",
      "x_1    0\n",
      "x_2    0\n",
      "y      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# It's important to check for the null values in both the training and the test dataset\n",
    "\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b703824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    400\n",
       "1.0    400\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the data entries of column y to see the types of labels\n",
    "# pandas.value_counts() function is used to print the number of distinct entries in a particular coulmn\n",
    "\n",
    "df_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41647072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.7594805 , 7.5079397 ],\n",
       "       [3.42205706, 4.99120267],\n",
       "       [2.77881751, 4.11207082],\n",
       "       ...,\n",
       "       [3.54410545, 2.64987938],\n",
       "       [2.57546055, 2.51725473],\n",
       "       [3.5608151 , 3.99184993]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperating the X and y of training data\n",
    "# pandas.values function converts the data of DataFrame into array\n",
    "\n",
    "X_train = df_train[['x_1', 'x_2']].values\n",
    "y_train = df_train['y'].values\n",
    "\n",
    "X_test = df_test[['x_1', 'x_2']].values\n",
    "y_test = df_test['y'].values\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed3347c",
   "metadata": {},
   "source": [
    "It is clear that this model has two labels 0 and 1. So Gaussian Discriminative Analysis would work fine for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533269af",
   "metadata": {},
   "source": [
    "### Declaring the modal parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc4548",
   "metadata": {},
   "source": [
    "In GDA model, the prediction is based on the basis of probabilities of the input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c2fa3",
   "metadata": {},
   "source": [
    "The probablity of the input data is calculated in the basis of three parameters; mu, sigma and phi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bba6fb",
   "metadata": {},
   "source": [
    "mu refers to the mean of the individual features of a particular class. So it will be a matrix of order d x 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab96c41",
   "metadata": {},
   "source": [
    "sigma refers to the covariance matrix of each class between its variuos features. So it will be a matrix of order d x d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ea406",
   "metadata": {},
   "source": [
    "phi refers to the probability of occurance each class in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2848fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of data\n",
    "# numpy.shape gives the number of rows and columns in a form of tuple\n",
    "# Here y_train.shpe[0] gives the shape of the y_train array and the zero index specifies the number of rows in it.\n",
    "\n",
    "n = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f90155e",
   "metadata": {},
   "source": [
    "Mean of the data is average of data inputs. It is ratio of the sum of the total correct entries and total number of entries.\n",
    "\n",
    "To calculate the mean of the features of the respective classes, firstly the classes should be divided into the respective groups on the bais of labels and then thier respective means should be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42dfae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the mean matrix\n",
    "# mu_0 represents the mean of the features belonging to class 0\n",
    "# Firstly the df_train is sorted according to the class labels\n",
    "# df_train['y'] == 0 will give true and false thereby distinguishing the dataset on the class labels\n",
    "# Then the respective features are selected to be meaned.\n",
    "# np.mean() calculates the mean of the input entries\n",
    "\n",
    "mu_0 = df_train[df_train['y'] == 0][['x_1', 'x_2']].mean()\n",
    "\n",
    "# mu_1 represents the mean of the features belonging to class 1\n",
    "# df_train['y'] == 1 will give true and false thereby distinguishing the dataset on the class labels\n",
    "\n",
    "mu_1 = df_train[df_train['y'] == 1][['x_1', 'x_2']].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6358c12",
   "metadata": {},
   "source": [
    "Phi is the probability of the occurance of the event. It is calculated by taking out the ratio of total no. of justified cases and the total no. of sample cases.\n",
    "\n",
    "To calculate the occurace probability of the event, the count of each class should be found out first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "053d4c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of phi\n",
    "# initialising phi as an array of zeros\n",
    "# numpy.shape gives the number of rows and columns in a form of tuple\n",
    "# Here y_train.shpe[0] gives the shape of the y_train array and the zero index specifies the number of rows in it.\n",
    "\n",
    "phi = np.zeros(y_train.shape[0])\n",
    "\n",
    "# df_train['y'] == 0 will give true and false thereby distinguishing the dataset on the class labels\n",
    "# .count() tells the total number of justified data as per the conditions if applied any\n",
    "\n",
    "n_0 = df_train[df_train['y'] == 0]['y'].count() # n_0=400\n",
    "n_1 = df_train[df_train['y'] == 1]['y'].count() # n_1=400\n",
    "phi[0] = n_0 / n                                # n_0 = 400; n = 800; phi[0] = 0.5\n",
    "phi[1] = n_1 / n                                # n_1 = 400; n = 800; phi[1] = 0.5\n",
    "\n",
    "# As we have a very standard data so the probability of occurance of both the classes are same\n",
    "# Therefore phi will not play any affect in determining the likely probability of the test features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fec72c",
   "metadata": {},
   "source": [
    "For Covariance, firstly individual covariances are calculated of individual classes and then the pooled covariance is calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b8b351b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Covariance matrix sigma and then pooled sigma\n",
    "# df_train['y'] == 0 will give true and false thereby distinguishing the dataset on the class labels\n",
    "# np.cov will calculate the covariance matrix  of the given data\n",
    "\n",
    "sigma_0 = df_train[df_train['y'] == 0][['x_1', 'x_2']].cov().values\n",
    "sigma_1 = df_train[df_train['y'] == 1][['x_1', 'x_2']].cov().values\n",
    "\n",
    "# Now the pooled sigma is calculated using the below formula\n",
    "\n",
    "pooled_sigma = (sigma_0 * (n_0 - 1) + sigma_1 * (n_1 - 1)) / (n_0 + n_1 - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2bc77006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigma_0\n",
      " [[0.93996737 0.65326934]\n",
      " [0.65326934 0.9372294 ]]\n",
      "Sigma_1\n",
      " [[1.01781642 0.74399449]\n",
      " [0.74399449 0.95598585]]\n",
      "Pooled_sigma\n",
      " [[0.9788919  0.69863192]\n",
      " [0.69863192 0.94660762]]\n"
     ]
    }
   ],
   "source": [
    "# Printing sigma_0, sigma_1 and pooled sigma\n",
    "\n",
    "print(\"Sigma_0\\n\", sigma_0)\n",
    "print(\"Sigma_1\\n\", sigma_1)\n",
    "print('Pooled_sigma\\n', pooled_sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a710502",
   "metadata": {},
   "source": [
    "Notice that in all the above sigmas the non-diagonal elements are the same.\n",
    "\n",
    "It is because it is calculated as follows:\n",
    "\n",
    "The first element of a sigma matrix is the covariance between the first and the first element.\n",
    "\n",
    "The second element of a sigma matrix is the covariance between the first and the second element.\n",
    "\n",
    "The third element of a sigma matrix is the covariance between the second and the first element.\n",
    "\n",
    "The fourth element of a sigma matrix is the covariance between the second and the second element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec64f422",
   "metadata": {},
   "source": [
    "### Defining the Gaussian Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a4f7ea",
   "metadata": {},
   "source": [
    "In this function, it calculates the likelihood of an input feature for both the classes\n",
    "\n",
    "Based on that information that input feature will be predicted to be the oart of the one with more likelihood value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23fc3330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Gaussian_Analysis Function\n",
    "# When it takes the X as input, it calculates it probability of belonging to both the classes\n",
    "# It returns 1 if the probability of it belonging to class 1 is more than the class 0\n",
    "# It returns 0 if the probability of it belonging to class 0 is more than the class 1\n",
    "\n",
    "def gaussian_analysis(x):\n",
    "    \n",
    "    # np.dot function is used to calculate the product of matrices\n",
    "    # np.linalg.inv() is uded to calculate the inverse of the sigma matrix\n",
    "    # Here pooled sigma is used beacuse it is assumed that both the gaussian distributions are based on the same covariance matrix\n",
    "    \n",
    "    # Calculating log likelihood for Class 0\n",
    "    # mu_0 represents the mean of class 0 of features x_1 and x_2\n",
    "    # phi[0] represents the probability of occurance of Class 0 in whole dataset\n",
    "    \n",
    "    prob_0 = -0.5 * np.dot(np.dot((x - mu_0).T, np.linalg.inv(pooled_sigma)), x - mu_0) + np.log(phi[0])\n",
    "    \n",
    "    # Calculating log likelihood for Class 1\n",
    "    # mu_1 represents the mean of class 1 of features x_1 and x_2\n",
    "    # phi[1] represents the probability of occurance of Class 1 in whole dataset\n",
    "    \n",
    "    prob_1 = -0.5 * np.dot(np.dot((x - mu_1).T, np.linalg.inv(pooled_sigma)), x - mu_1) + np.log(phi[1])\n",
    "    \n",
    "    # The probability of both the classes are compared and thus returns the class label to which it should belong\n",
    "    \n",
    "    if prob_0 < prob_1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e22024",
   "metadata": {},
   "source": [
    "### Predicting output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ce1480",
   "metadata": {},
   "source": [
    "After defining the function its time to predict the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "623f43f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training data:  0.91375\n",
      "Accuracy of test data:  0.91\n"
     ]
    }
   ],
   "source": [
    "# Initialisng the variable that will keep the count of correct predicted data\n",
    "# len() function calculates the length of the list \n",
    "\n",
    "correct_train = 0\n",
    "for i in range(len(y_train)):\n",
    "    if gaussian_analysis(X_train[i]) == y_train[i]:\n",
    "        correct_train = correct_train + 1\n",
    "print('Accuracy of training data: ',correct_train / len(y_train))\n",
    "\n",
    "correct_test = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    if gaussian_analysis(X_test[i]) == y_test[i]:\n",
    "        correct_test = correct_test + 1\n",
    "print('Accuracy of test data: ',correct_test / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78711547",
   "metadata": {},
   "source": [
    "The accuracy of training dataset by the above model is 0.91375\n",
    "\n",
    "The accuracy of test dataset by the above model is 0.91"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
