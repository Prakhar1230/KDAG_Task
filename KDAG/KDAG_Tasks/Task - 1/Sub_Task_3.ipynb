{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3883a49",
   "metadata": {},
   "source": [
    "# Hyperparameter_Tuning of Logistic_Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146efe2a",
   "metadata": {},
   "source": [
    "#### In this subtask, hyperparameters are tuned using scikit learn library "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51b0f56",
   "metadata": {},
   "source": [
    "Numpy is used to create array and its functions are used such as exponential function, dot product, transpose of a matrix etc.\n",
    "\n",
    "Pandas is used to read data from the csv files and convert it into list of arrays.\n",
    "\n",
    "sklearn.linear_model provides the LogisticRegression model with its builtin features\n",
    "\n",
    "sklearn.model_selection provides GridSearchCV which gives the best hyperparameter for the model which will predict results with highest accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72bae144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c398cb1",
   "metadata": {},
   "source": [
    "The data from the csv files are extracted by pandas.read_csv function where it reads the data from the csv file and converts it into the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8412894c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the traning and test examples\n",
    "# df_train represents the traning DataFrame\n",
    "\n",
    "df_train = pd.read_csv('ds1_train.csv')\n",
    "df_test = pd.read_csv('ds1_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af75f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.911809</td>\n",
       "      <td>60.359613</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.774746</td>\n",
       "      <td>344.149284</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.615488</td>\n",
       "      <td>178.222087</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.013694</td>\n",
       "      <td>15.259472</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.757625</td>\n",
       "      <td>66.194174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.973922</td>\n",
       "      <td>41.677665</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.067275</td>\n",
       "      <td>143.275590</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.763094</td>\n",
       "      <td>35.969906</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.775772</td>\n",
       "      <td>29.569079</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.109830</td>\n",
       "      <td>76.636721</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        x_1         x_2    y\n",
       "0  2.911809   60.359613  0.0\n",
       "1  3.774746  344.149284  0.0\n",
       "2  2.615488  178.222087  0.0\n",
       "3  2.013694   15.259472  0.0\n",
       "4  2.757625   66.194174  0.0\n",
       "5  0.973922   41.677665  0.0\n",
       "6  3.067275  143.275590  0.0\n",
       "7  2.763094   35.969906  0.0\n",
       "8  2.775772   29.569079  0.0\n",
       "9  2.109830   76.636721  0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the datframe df_train to see the type of data\n",
    "# pandas.head(n) function is used to print the first n data entries of the respective dataframe. By default n=5\n",
    "\n",
    "df_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9531620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_1    0\n",
      "x_2    0\n",
      "y      0\n",
      "dtype: int64\n",
      "x_1    0\n",
      "x_2    0\n",
      "y      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# It's important to check for the null values in both the training and the test dataset\n",
    "\n",
    "print(df_train.isnull().sum())\n",
    "print(df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8029884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    400\n",
       "1.0    400\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing the data entries of column y to see the types of labels\n",
    "# pandas.value_counts() function is used to print the number of distinct entries in a particular coulmn\n",
    "\n",
    "df_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4f7214d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing the total number of entries in a column\n",
    "# pandas.count() is used to show the total number of entries in a column\n",
    "\n",
    "df_train['y'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e2e807",
   "metadata": {},
   "source": [
    "From the above few run tests, it is clear our dataset has 3 columns named as 'x_1', 'x_2' and y.\n",
    "The total number of entries are 800. Column 'y' has only two labels 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084cff45",
   "metadata": {},
   "source": [
    "It's clear that the above dataset has only two types of data labesl i.e. 0 and 1. In such a case, Logistic Regression is a good model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a580281",
   "metadata": {},
   "source": [
    "As it is a Logistic Regression model, we need a columnn lablled as 'x_0' with data entries equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "14530b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.        ,   2.91180854,  60.35961272],\n",
       "       [  1.        ,   3.77474554, 344.1492843 ],\n",
       "       [  1.        ,   2.61548828, 178.22208681],\n",
       "       ...,\n",
       "       [  1.        ,   2.96909526,  20.24997848],\n",
       "       [  1.        ,   3.95753102,  27.26196973],\n",
       "       [  1.        ,   4.02533402,  12.23316511]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a column of data entries as 1\n",
    "\n",
    "df_train['x_0'] = 1\n",
    "df_test['x_0'] = 1\n",
    "\n",
    "# Seperating the X and y of training data\n",
    "# pandas.values function converts the data of DataFrame into array\n",
    "\n",
    "X_train = df_train[['x_0', 'x_1', 'x_2']].values\n",
    "y_train = df_train['y'].values\n",
    "\n",
    "X_test = df_test[['x_0', 'x_1', 'x_2']].values\n",
    "y_test = df_test['y'].values\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd5a9f9",
   "metadata": {},
   "source": [
    "For reference, Logistic Regression function uses sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "40e70474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Logistic Regression hypothesis function is the sigmoid function\n",
    "# Defining the sigmoid function\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e47f0c",
   "metadata": {},
   "source": [
    "It's time for the gradient ascent function in which theta will be updated everytime the loop runs.\n",
    "\n",
    "alpha is the learning rate and num_iter is the number of iterations the loop runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8a4a21d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring gradient ascent function\n",
    "# array.shape gives the dimensions of array\n",
    "\n",
    "def gradient_ascent(X, y, alpha, num_iter):\n",
    "    \n",
    "    m, n = X.shape()\n",
    "    \n",
    "    # Declaring theta as an array of zeros\n",
    "    # numpy.zeros(n) creates a single dimensional array of n columns and 1 row\n",
    "    \n",
    "    theta = np.zeros(n)\n",
    "    \n",
    "    # The following for loop calculates the theta value required for prediction\n",
    "    # The transpose function is not used beacuse the theta array created above is already in its transposed form as per the theory.\n",
    "    \n",
    "    # numpy.dot does the dot product of matrices\n",
    "    # It calculates the sigmoid value from the sigmoid function and then calculates the dot product\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        h = sigmoid(np.dot(X,theta))\n",
    "        \n",
    "        # h is the sigmoid value calculated and y is the value taken from the signature of gradient_ascent function\n",
    "        \n",
    "        gradient = np.dot(X_train.T, h - y) / m_train \n",
    "        theta = theta - alpha * gradient\n",
    "    return theta\n",
    "\n",
    "# This function thus returns theta "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7edcf4",
   "metadata": {},
   "source": [
    "### LogisticRegression() has many hyperparameter values such as penalty, solver and C."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7274e4",
   "metadata": {},
   "source": [
    "'alpha' is , the learning rate, a hyperparameter used in optimization algorithms, such as gradient descent, to control the step size at each iteration when updating the model's parameters during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326714a",
   "metadata": {},
   "source": [
    "The number of iterations, often referred to as \"epochs\" or \"iterations,\" is a critical hyperparameter that determines how many times the learning algorithm will update the model's parameters during training. Each iteration involves passing the entire training dataset through the algorithm and updating the model's parameters based on the gradients of the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a4e0be",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb59351",
   "metadata": {},
   "source": [
    "GridSearch is a technique for hyperparameter tuning and model selection in machine learning. It is a systematic way of searching through a predefined set of hyperparameter values to find the combination that yields the best model performance. GridSearch is commonly used to optimize the hyperparameters of a machine learning model and improve its generalization on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9ac065",
   "metadata": {},
   "source": [
    "In the following function; for loops goes through every value of alpha and number of iterations and calculate the theta corresponding to those values. Thereafter it trains the model and calculates the acuracy of both the training and test dataset and print it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d5974cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining GridSearch function\n",
    "# It takes many parameters such as X_train, y_train, X_test, y_test, alpha, num_iter\n",
    "# X_train is the traning set and contains features to be trained\n",
    "# y_train is the training set column and conatins labels to be compared with\n",
    "# X_test is the traning set and contains features to be trained\n",
    "# y_test is the training set column and conatins labels to be compared with\n",
    "# alpha is the learning rate hyperparameter\n",
    "# num_iter is the number of iterations hyperparameter\n",
    "\n",
    "def GridSearch(X_train, y_train, X_test, y_test, alpha, num_iter):\n",
    "    \n",
    "    # Initialising each calculating term to zero\n",
    "    \n",
    "    max_accur = 0\n",
    "    max_accur_iter = 0\n",
    "    max_accur_alpha = 0\n",
    "    max_accur_theta = np.zeros(3)\n",
    "    \n",
    "    # Implementing GridSearch\n",
    "    # Defining the for loop to run \n",
    "    # First loop is the loop running through alpha parameters list\n",
    "    # Second loop is the loop running through number of iterations parameters list\n",
    "    \n",
    "    # a will be running through every term of alpha list\n",
    "    \n",
    "    for a in alpha:\n",
    "        \n",
    "        # iter will be running through num_iter list\n",
    "        \n",
    "        for iter in num_iter:\n",
    "            \n",
    "            # Calculating theta by calling gradient_ascent function\n",
    "            \n",
    "            theta = gradient_ascent(X_train, y_train, a, iter)\n",
    "\n",
    "            # Calculating the sigmoid values and accuracy\n",
    "            \n",
    "            h_train = sigmoid(X_train.dot(theta))\n",
    "            y_pred_train = (h_train >= 0.5).astype(int)\n",
    "            train_accur = np.mean(y_pred_train == y_train)\n",
    "            print('Accur: ', a, ' ', iter, ' ', train_accur)\n",
    "            \n",
    "            # Compares the training accuracy\n",
    "\n",
    "            if train_accur >= max_accur:\n",
    "                max_accur = train_accur\n",
    "                max_accur_iter = iter\n",
    "                max_accur_alpha = a\n",
    "                max_accur_theta = theta\n",
    "\n",
    "    # Calculating accuracy on the test set and printing it \n",
    "    \n",
    "    h_test = sigmoid(X_test.dot(max_accur_theta))\n",
    "    y_pred_test = (h_test >= 0.5).astype(int)\n",
    "    test_accuracy = np.mean(y_pred_test == y_test)\n",
    "    \n",
    "    # Returning the calculated parameters\n",
    "\n",
    "    return max_accur, max_accur_iter, max_accur_alpha, max_accur_theta, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "728ccec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the alpha and num_iter parameters\n",
    "\n",
    "alpha = [0.001, 0.01, 0.1]\n",
    "num_iter = [10000, 100000, 200000, 300000, 400000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4715819f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accur:  0.001   10000   0.8\n",
      "Accur:  0.001   100000   0.8925\n",
      "Accur:  0.001   200000   0.8925\n",
      "Accur:  0.001   300000   0.88125\n",
      "Accur:  0.001   400000   0.88125\n",
      "Accur:  0.01   10000   0.78\n",
      "Accur:  0.01   100000   0.8775\n",
      "Accur:  0.01   200000   0.84625\n",
      "Accur:  0.01   300000   0.84875\n",
      "Accur:  0.01   400000   0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prakh\\AppData\\Local\\Temp\\ipykernel_27260\\814328648.py:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1/(1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accur:  0.1   10000   0.6525\n",
      "Accur:  0.1   100000   0.87625\n",
      "Accur:  0.1   200000   0.87875\n",
      "Accur:  0.1   300000   0.88375\n",
      "Accur:  0.1   400000   0.87875\n"
     ]
    }
   ],
   "source": [
    "# Calculating the required parameters from GridSearch\n",
    "\n",
    "max_accur, max_accur_iter, max_accur_alpha, max_accur_theta, test_accuracy = GridSearch(X_train, y_train, X_test, y_test, alpha, num_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1fdc2d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "Iterations: 200000\n",
      "Learning Rate: 0.001\n",
      "Training Accuracy: 0.8925\n",
      "Test Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "# Printing the best parameters\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "print(\"Iterations:\", max_accur_iter)\n",
    "print(\"Learning Rate:\", max_accur_alpha)\n",
    "print(\"Training Accuracy:\", max_accur)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4dbec1c",
   "metadata": {},
   "source": [
    "Therefore, the best hyperparmeters are:\n",
    "    \n",
    "alpha = 0.001\n",
    "\n",
    "num_iter = 200000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0711c5a",
   "metadata": {},
   "source": [
    "## Thank You"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
